{
  "papers": [
    {
      "id": "paper006",
      "title": "RegGS: Unposed Sparse Views Gaussian Splatting with 3DGS Registration",
      "title_zh": "RegGS：基于3DGS配准的无位姿稀疏视角高斯散射",
      "authors": ["Chong Cheng", "Yu Hu", "Sicheng Yu", "Beizhen Zhao", "Zijian Wang", "Hao Wang"],
      "venue": "ICCV 2025",
      "year": "2025",
      "status": "published",
      "status_text": "已发表",
      "group": "3d",
      "tags": ["3D Vision", "Gaussian Splatting", "Registration"],
      "abstract": "3D Gaussian Splatting (3DGS) has demonstrated its potential in reconstructing scenes from unposed images. However, optimization-based 3DGS methods struggle with sparse views due to limited prior knowledge. Meanwhile, feed-forward Gaussian approaches are constrained by input formats, making it challenging to incorporate more input views. To address these challenges, we propose RegGS, a 3D Gaussian registration-based framework for reconstructing unposed sparse views. RegGS aligns local 3D Gaussians generated by a feed-forward network into a globally consistent 3D Gaussian representation. Technically, we implement an entropy-regularized Sinkhorn algorithm to efficiently solve the optimal transport Mixture 2-Wasserstein distance, which serves as an alignment metric for Gaussian mixture models in Sim(3) space. Furthermore, we design a joint 3DGS registration module that integrates the MW2 distance, photometric consistency, and depth geometry. This enables a coarse-to-fine registration process while accurately estimating camera poses and aligning the scene. Experiments on the RE10K and ACID datasets demonstrate that RegGS effectively registers local Gaussians with high fidelity, achieving precise pose estimation and high-quality novel-view synthesis.",
      "abstract_zh": "3D高斯散射在从无位姿图像重建场景方面展现了潜力。然而，基于优化的3DGS方法由于先验知识有限而难以处理稀疏视角。同时，前馈高斯方法受输入格式限制，难以融合更多输入视角。为应对这些挑战，我们提出RegGS，一个基于3D高斯配准的无位姿稀疏视角重建框架。RegGS将前馈网络生成的局部3D高斯对齐为全局一致的表示。技术上，我们实现了熵正则化Sinkhorn算法来高效求解最优传输Mixture 2-Wasserstein距离，作为Sim(3)空间中高斯混合模型的对齐度量。此外，我们设计了联合3DGS配准模块，整合MW2距离、光度一致性和深度几何。这实现了从粗到精的配准过程，同时准确估计相机位姿并对齐场景。在RE10K和ACID数据集上的实验表明，RegGS有效地以高保真度配准局部高斯，实现精确位姿估计和高质量新视角合成。",
      "pdf_url": "https://3dagentworld.github.io/RegGS/",
      "code_url": "https://github.com/3DAgentWorld/RegGS",
      "project_url": "https://3dagentworld.github.io/RegGS/",
      "bibtex": "@inproceedings{cheng2025reggs,\n  title={RegGS: Unposed Sparse Views Gaussian Splatting with 3DGS Registration},\n  author={Cheng, Chong and Hu, Yu and Yu, Sicheng and Zhao, Beizhen and Wang, Zijian and Wang, Hao},\n  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},\n  year={2025}\n}",
      "thumbnail": "images/papers/paper006.jpg"
    },
    {
      "id": "paper005",
      "title": "Outdoor Monocular SLAM with Global Scale-Consistent 3D Gaussian Pointmaps",
      "title_zh": "基于全局尺度一致3D高斯点云图的户外单目SLAM",
      "authors": ["Chong Cheng", "Sicheng Yu", "Zijian Wang", "Yifan Zhou", "Hao Wang"],
      "venue": "ICCV 2025",
      "year": "2025",
      "status": "published",
      "status_text": "已发表",
      "group": "3d",
      "tags": ["SLAM", "Gaussian Splatting", "Outdoor"],
      "abstract": "3D Gaussian Splatting (3DGS) has become a popular solution in SLAM due to its high-fidelity and real-time novel view synthesis performance. However, some previous 3DGS SLAM methods employ a differentiable rendering pipeline for tracking, lack geometric priors in outdoor scenes. Other approaches introduce separate tracking modules, but they accumulate errors with significant camera movement, leading to scale drift. To address these challenges, we propose a robust RGB-only outdoor 3DGS SLAM method: S3PO-GS. Technically, we establish a self-consistent tracking module anchored in the 3DGS pointmap, which avoids cumulative scale drift and achieves more precise and robust tracking with fewer iterations. Additionally, we design a patch-based pointmap dynamic mapping module, which introduces geometric priors while avoiding scale ambiguity. This significantly enhances tracking accuracy and the quality of scene reconstruction, making it particularly suitable for complex outdoor environments. Our experiments on the Waymo, KITTI, and DL3DV datasets demonstrate that S3PO-GS achieves state-of-the-art results in novel view synthesis and outperforms other 3DGS SLAM methods in tracking accuracy.",
      "abstract_zh": "3D高斯散射因其高保真和实时新视角合成性能而成为SLAM中的流行解决方案。然而，一些先前的3DGS SLAM方法采用可微渲染管道进行跟踪，在户外场景中缺乏几何先验。其他方法引入单独的跟踪模块，但在相机大幅移动时会累积误差，导致尺度漂移。为应对这些挑战，我们提出了一种鲁棒的纯RGB户外3DGS SLAM方法：S3PO-GS。技术上，我们建立了锚定在3DGS点云图中的自一致跟踪模块，避免累积尺度漂移，以更少迭代实现更精确和鲁棒的跟踪。此外，我们设计了基于块的点云图动态映射模块，在引入几何先验的同时避免尺度歧义。这显著提高了跟踪精度和场景重建质量，特别适合复杂的户外环境。在Waymo、KITTI和DL3DV数据集上的实验表明，S3PO-GS在新视角合成中达到最先进的结果，并在跟踪精度上优于其他3DGS SLAM方法。",
      "pdf_url": "https://arxiv.org/abs/2507.03737",
      "code_url": "https://github.com/3DAgentWorld/S3PO-GS",
      "project_url": "https://3dagentworld.github.io/S3PO-GS/",
      "bibtex": "@article{cheng2025outdoor,\n  title={Outdoor Monocular SLAM with Global Scale-Consistent 3D Gaussian Pointmaps},\n  author={Cheng, Chong and Yu, Sicheng and Wang, Zijian and Zhou, Yifan and Wang, Hao},\n  journal={arXiv preprint arXiv:2507.03737},\n  year={2025}\n}",
      "thumbnail": "images/papers/paper005.jpg"
    },
    {
      "id": "paper004",
      "title": "RGB-Only Gaussian Splatting SLAM for Unbounded Outdoor Scenes",
      "title_zh": "面向无界户外场景的纯RGB高斯散射SLAM",
      "authors": ["Sicheng Yu", "Chong Cheng", "Yifan Zhou", "Xiaojun Yang", "Hao Wang"],
      "venue": "ICRA 2025",
      "year": "2025",
      "status": "published",
      "status_text": "已发表",
      "group": "3d",
      "tags": ["SLAM", "Gaussian Splatting", "Outdoor"],
      "abstract": "3D Gaussian Splatting (3DGS) has become a popular solution in SLAM, as it can produce high-fidelity novel views. However, previous GS-based methods primarily target indoor scenes and rely on RGB-D sensors or pre-trained depth estimation models, hence underperforming in outdoor scenarios. To address this issue, we propose a RGB-only gaussian splatting SLAM method for unbounded outdoor scenes—OpenGS-SLAM. Technically, we first employ a pointmap regression network to generate consistent pointmaps between frames for pose estimation. Our experiments on the Waymo dataset demonstrate that OpenGS-SLAM reduces tracking error to 9.8% of previous 3DGS methods, and achieves state-of-the-art results in novel view synthesis.",
      "abstract_zh": "3D高斯散射在SLAM中已成为流行解决方案，能够生成高保真新视角。然而，以往基于GS的方法主要针对室内场景，依赖RGB-D传感器或预训练深度估计模型，在户外场景表现不佳。我们提出OpenGS-SLAM，一种面向无界户外场景的纯RGB高斯散射SLAM方法。在Waymo数据集上的实验表明，OpenGS-SLAM将跟踪误差降低到以往3DGS方法的9.8%，并在新视角合成中达到最先进水平。",
      "pdf_url": "https://arxiv.org/abs/2502.15633",
      "code_url": "https://github.com/3DAgentWorld/OpenGS-SLAM",
      "project_url": "https://3dagentworld.github.io/opengs-slam/",
      "bibtex": "@inproceedings{yu2025opengsslam,\n  title={RGB-Only Gaussian Splatting SLAM for Unbounded Outdoor Scenes},\n  author={Yu, Sicheng and Cheng, Chong and Zhou, Yifan and Yang, Xiaojun and Wang, Hao},\n  booktitle={IEEE International Conference on Robotics and Automation (ICRA)},\n  year={2025}\n}",
      "thumbnail": "images/papers/paper004.jpg"
    },
    {
      "id": "paper003",
      "title": "GVKF: Gaussian Voxel Kernel Functions for Highly Efficient Surface Reconstruction in Open Scenes",
      "title_zh": "GVKF：用于开放场景高效表面重建的高斯体素核函数",
      "authors": ["Gaochao Song", "Chong Cheng", "Hao Wang"],
      "venue": "NeurIPS 2024",
      "year": "2024",
      "status": "published",
      "status_text": "已发表",
      "group": "3d",
      "tags": ["Surface Reconstruction", "Gaussian Splatting", "NeRF"],
      "abstract": "In this paper we present a novel method for efficient and effective 3D surface reconstruction in open scenes. Existing Neural Radiance Fields (NeRF) based works typically require extensive training and rendering time due to the adopted implicit representations. In contrast, 3D Gaussian splatting (3DGS) uses an explicit and discrete representation, hence the reconstructed surface is built by the huge number of Gaussian primitives, which leads to excessive memory consumption and rough surface details in sparse GS areas. To address these issues, we propose Gaussian Voxel Kernel Functions (GVKF), which establish a continuous scene representation based on discrete 3D Gaussian Splatting (3DGS) through kernel regression.",
      "abstract_zh": "本文提出了一种用于开放场景高效3D表面重建的新方法。现有基于NeRF的方法由于采用隐式表示，通常需要大量训练和渲染时间。相比之下，3D高斯散射使用显式离散表示，但重建表面需要大量高斯基元，导致内存消耗过大。我们提出高斯体素核函数(GVKF)，通过核回归建立基于离散3DGS的连续场景表示。",
      "pdf_url": "https://arxiv.org/abs/2411.01853",
      "code_url": "https://github.com/3DAgentWorld/GVKF",
      "project_url": "https://3dagentworld.github.io/gvkf/",
      "bibtex": "@misc{song2024gvkfgaussianvoxelkernel,\n  title={GVKF: Gaussian Voxel Kernel Functions for Highly Efficient Surface Reconstruction in Open Scenes},\n  author={Gaochao Song and Chong Cheng and Hao Wang},\n  year={2024},\n  eprint={2411.01853},\n  archivePrefix={arXiv},\n  primaryClass={cs.CV},\n  url={https://arxiv.org/abs/2411.01853}\n}",
      "thumbnail": "images/papers/paper003.jpg"
    }
  ]
}
